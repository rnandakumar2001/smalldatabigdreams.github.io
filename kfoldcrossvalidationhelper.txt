#k fold Cross Validation
import numpy as np
from sklearn.model_selection import KFold

def k_fold_cross_validation(model, X, y, k=5):
    """
    Perform K-Fold Cross-Validation.

    Parameters:
        model: The machine learning model to be evaluated.
        X: Input features as a 2D array or DataFrame.
        y: Target labels as a 1D array or Series.
        k: Number of folds (default is 5).

    Returns:
        scores: A list of performance metrics for each fold.
    """

    kf = KFold(n_splits=k, shuffle=True, random_state=42)
    scores = []

    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # Train the model
        model.fit(X_train, y_train)

        # Evaluate the model
        score = model.score(X_test, y_test)
        scores.append(score)

    return scores

# # Example usage:
# from sklearn.linear_model import LinearRegression
# from sklearn.datasets import load_diabetes

# # Load dataset
# diabetes = load_diabetes()
# X, y = diabetes.data, diabetes.target

# # Create a model (e.g., Linear Regression)
# model = LinearRegression()

# # Perform K-Fold Cross-Validation
# scores = k_fold_cross_validation(model, X, y)

# # Print the average performance metric
# print("Average R2 score:", np.mean(scores))